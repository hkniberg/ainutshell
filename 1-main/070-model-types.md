# Model types

Note that there are different types of Generative AI models that generate different types of content.

## Text to Text

![](../.gitbook/assets/070-text-to-text.png)

Text to Text models, like GPT 4, take text as input and generate text as output. The text can be natural language, but it can also be structured information like code, json or html. I use this a lot to generate code when programming, it saves an incredible amount of time, and I also learn a lot from the code it generates.

## Text to Image

![](../.gitbook/assets/070-text-to-image.png)

Text to Image models will generate images. Describe what you want and an image gets generated for you.

This isn't clip art. Each image is uniquely generated from scratch.

For example here are four variants of the same ugly cat, with different facial expressions.

![](../.gitbook/assets/070-ugly-cat-x4.png)

(Yes, bottom left is her happy face)

You can even pick a style.

![](../.gitbook/assets/070-styles.png)

Or how about an ugly cat in a couch smoking a pipe?

![alt text](../.gitbook/assets/070-ugly-cat-smoking-pipe.png)

## Image to Image

Image to Image models can do things like transforming or combining images. Let's combine "Einstiein the Basement" with "Ugly Cat". Sorry that you won't be able to unsee this...

![](../.gitbook/assets/070-image-to-image.png)

## Image to Text

Image to Text models can be used to classify images ("does this contain a cat"), or describt the contents of a given image. I was surprised that an AI model managed to recognize the contents of the merged image above...

![alt text](../.gitbook/assets/070-image-to-text.png)

OK that was the last cat picture, I promise!

## Audio to text

Audio to text models (sometimes called speech to text) can do things like voice transcriptions and meeting notes, which is very useful. When writing this book, I used speech to text all the time, to capture my thoughts while I was out walking. Speech to text models have been around for a long time, but when OpenAI released their Whisper model, it suddenly became incredibly good at understanding speech, even in noisy environments.

![](../.gitbook/assets/070-audio-to-text.png)

## Text to audio

Text to Audio models can generate music or sounds. For example to generate a jingle for a video "Upbeat jingle with a catchy tune and a slap bass solo in the middle", or read a text out loud because you are out walking and don't want to read, or generate sound effects like "people walking in a busy restaurant" or "That horrible screeching sound of chalk on a blackboard" (OK please don't use that last one).

![](../.gitbook/assets/070-text-to-audio.png)

As a hobby musician, I wouldn't use this to replace myself as a musician, because I _like_ playing music. But I might use it to generate ideas for grooves and song styles, or quickly explore different variations or instrumentations.

## Text to video

There are even Text to Video models that generate videos from a prompt. This is a book so I can't really show it, but imagine these as beautifully rendered videos.

![](../.gitbook/assets/070-text-to-video-1.png)

![](../.gitbook/assets/070-text-to-video-2.png)

Sooner or later weâ€™ll have infinite movie series that autogenerate the next episode tailored to your tastes, as you are watching. Kind of scary if you think about it.

> ![alt text](../.gitbook/assets/egbert-small.png) **Egbert's take**  
> Ah, perfect! When aliens finally visit Earth, they'll find the remnants of human civilization: skeletons slumped on sofas, eyes fixed on screens. Cause of extinction? Starvation, because no one could tear themselves away from their personalized, never-ending Netflix series.
