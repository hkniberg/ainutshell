# Emergent capabilities

Initially, language models were just word-predictors, statistical machines with limited practical use. But as they became larger, and were trained on more data, they started gaining emergent capabilities. Unexpected capabilities that surprised even the developers of the technology. They could role-play, write poetry, write high quality code, discuss company strategy, provide legal and medical advice, coach, teach. Creative and intellectual things that only humans could do previously.

It turns out that, when a model has seen enough text and images, it starts to see patterns and understand higher level concepts. Just like a baby learning to understand the world.

Let’s take a simple example. I’ll give GPT4 a little drawing that involves a string, a pair of scissors, an egg, a pot and a fire. What will happen if I use the scissors? The model has probably not been trained on this exact scenario, yet it gave a pretty good answer, which demonstrates a basic understanding of the nature of scissors, eggs, gravity, and heat.

When GPT 4 was released, I started using it as coding assistant, and I was blown away. When prompted effectively, it was a better programmer than anyone I’ve worked with. Same with article writing, product design, workshop planning, and just about anything I used it for. The main bottleneck was my prompt engineering skills.

So, I decided to make a career shift and focus entirely on learning and teaching how to make this technology useful. Hence, this video.
